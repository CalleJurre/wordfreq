def tokenize(lines):
    words = []
    for line in lines:
        start = 0
        while start < len(line):
            if not line[start].isspace():
                #print(line[start])
                if line[start].isdigit():
                    print (f'{line[start]} is a digit')
                elif line[start].isalpha():
                    print (f'{line[start]} is a letter')
                else:
                    print (f'{line[start]} is a symbol')
            start += 1
    return words


lines = ['    1sweet  apple.,  tart Ã¤r gott']
tokenize(lines)
